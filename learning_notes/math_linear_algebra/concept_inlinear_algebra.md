## 0. 本次学习的核心主题（Topic）
学线性代数的方式:
* 第一步：建立几何直觉
向量 = 空间里的箭头
矩阵 = 对空间的拉伸/旋转/投影
行列式 = 变换后的"体积缩放比"
特征向量 = 变换后"方向不变"的向量
* 第二步：理解"为什么要这样算"
为什么要算特征值？ → 找系统的"本质频率"
为什么要做SVD？ → 把变换分解成"旋转+拉伸+旋转"
为什么要正交化？ → 找一组"互相垂直"的基
* 第三步：连接到应用
AI里的应用 → 每个操作对应什么几何变换？
物理里的应用 → 为什么这个系统能写成矩阵形式？
* 按照"第一性原理学习法"：
先理解"线性代数的公理是什么"（向量空间的定义）
再理解"为什么要研究线性变换"（因为它是最简单的）
最后理解"各种定理在解决什么问题"


---

## 1. 公理 / 定义区（Axioms & Definitions）

* 正定性:从能量（Energy）和物理系统（Physical System）的角度来看，
    $x^T A x > 0$（即矩阵 $A$ 正定 Positive Definite）这一条件，
    描述的是一个系统的稳定性（Stability）和度量（Metric）的合法性。


* 空间变换(矩阵乘法):保持直线性(它和保持正交有什么关系?)
* 向量(特征值):
* 协方差conv(X,Y)：E((X-EX)(Y-EY));
  - 两个变量 X 和 Y 的“偏移量”拿来比一比，看它们是不是一起往上、一起往下当 X 离它的平均值更高时，Y 是否也更高？当 X 更低时，Y 是否也更低？把这个趋势的平均量算出来，就是协方差。
  - 它测的不是大小，而是共振方式。
  - 正协方差：一起涨，一起跌。负协方差：一个涨，另一个跌。零协方差：它们的涨跌和对方无关。
  - 泛化到高维:两个N维向量,
      - 协方差矩阵:每个位置都是i维和j维的协方差
      - 整个空间整体是怎么一起变动的,"数据的时空结构"
* 特征值/特征向量？
* 矩阵分解？矩阵分解？（SVD、PCA）把高维数据投影到低维空间,保留最重要的信息,这就是"降维" ← 线性代数的核心应用
* 向量空间的定义？
* Key Definition 2：
* 数学或概念公理：

---

## 2. 这个概念被发明的历史背景（Historical Motivation）

很多物理系统可以近似成线性系统：
例子1：振动系统
弹簧、摆、电路...都可以写成微分方程
多个振子耦合 → 矩阵形式
求解 → 特征值、特征向量

例子2：量子力学
量子态 = 向量
物理量 = 算符（矩阵）
测量 = 向量在特征向量上的投影

例子3：控制系统（verse你学过的！）
状态空间表示 → 矩阵形式
系统稳定性 → 特征值
最优控制 → 矩阵优化

* "最简单的非平凡结构"
太简单（比如加法）→ 描述不了复杂现象
太复杂（比如非线性）→ 算不出来、没有通用方法
线性代数：
足够简单 → 有通用的求解方法（矩阵分解、特征值...）
足够强大 → 能描述很多现象（至少是"一阶近似"）
性质：
线性系统可以叠加
可以分解成简单部分（特征向量）
每个部分独立处理后再组合


> 为什么会有这个方法、模型、损失函数、架构？
> 当年它是为了解决什么问题？

* 背景：
* 谁提出的：
* 早期版本长什么样：
* 解决了什么痛点：


